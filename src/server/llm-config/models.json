{
  "openai": {
    "paper_summary": {
      "model": "gpt-4o-mini",
      "rationale": "Cost-effective ($0.15/$0.6 per 1M tokens) with excellent quality for structured summaries. 128K context window handles full papers.",
      "pricing": {
        "input_per_1m": 0.15,
        "output_per_1m": 0.6
      }
    },
    "selection_summary": {
      "model": "gpt-4o-mini",
      "rationale": "Fast and cost-effective for short inline summaries. Balances speed and quality.",
      "pricing": {
        "input_per_1m": 0.15,
        "output_per_1m": 0.6
      }
    },
    "qa": {
      "model": "gpt-4o-mini",
      "rationale": "Excellent reasoning capabilities at low cost. Good for grounded Q&A with citations.",
      "pricing": {
        "input_per_1m": 0.15,
        "output_per_1m": 0.6
      }
    },
    "default": {
      "model": "gpt-4o-mini",
      "rationale": "Default fallback model for any task type not explicitly configured."
    }
  },
  "anthropic": {
    "paper_summary": {
      "model": "claude-3-haiku-20240307",
      "rationale": "Most cost-effective option ($0.25/$1.25 per 1M tokens). Fast with 200K context window. Excellent for high-volume summarization.",
      "pricing": {
        "input_per_1m": 0.25,
        "output_per_1m": 1.25
      }
    },
    "selection_summary": {
      "model": "claude-3-haiku-20240307",
      "rationale": "Ultra-fast and cheap for inline summaries. Perfect for quick context extraction.",
      "pricing": {
        "input_per_1m": 0.25,
        "output_per_1m": 1.25
      }
    },
    "qa": {
      "model": "claude-3-5-sonnet-20241022",
      "rationale": "Best reasoning capabilities for complex Q&A. Higher cost but superior for understanding nuanced research questions.",
      "pricing": {
        "input_per_1m": 3.0,
        "output_per_1m": 15.0
      }
    },
    "default": {
      "model": "claude-3-haiku-20240307",
      "rationale": "Default fallback - cost-effective option."
    }
  },
  "gemini": {
    "paper_summary": {
      "model": "gemini-1.5-flash",
      "rationale": "Excellent for long documents with 1M token context. Cost-effective ($0.075/$0.3 per 1M tokens) for paper summarization.",
      "pricing": {
        "input_per_1m": 0.075,
        "output_per_1m": 0.3
      }
    },
    "selection_summary": {
      "model": "gemini-1.5-flash",
      "rationale": "Fast and very cheap. Ideal for quick inline summaries.",
      "pricing": {
        "input_per_1m": 0.075,
        "output_per_1m": 0.3
      }
    },
    "qa": {
      "model": "gemini-1.5-pro",
      "rationale": "Better reasoning for complex Q&A tasks. Higher quality responses for research questions.",
      "pricing": {
        "input_per_1m": 1.25,
        "output_per_1m": 5.0
      }
    },
    "default": {
      "model": "gemini-1.5-flash",
      "rationale": "Default fallback - most cost-effective option."
    }
  },
  "notes": {
    "selection_strategy": "Models chosen based on cost-effectiveness and task-specific requirements. Summarization tasks prioritize cost while Q&A prioritizes reasoning quality.",
    "customization": "Override specific models by setting environment variables: {PROVIDER}_{TASK}_MODEL (e.g., OPENAI_QA_MODEL=gpt-4o)",
    "update_date": "2024-12-19"
  }
}

